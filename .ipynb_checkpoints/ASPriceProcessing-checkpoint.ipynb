{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import glob\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AS Datasets DAM\n",
    "#31 days, 24 hours $/MW\n",
    "#data set includes hourly value, should interpolate to 4\n",
    "\n",
    "#RD/RU DAM\n",
    "dfAsRDdamPrices=pd.read_csv(\"Data/AS_Prices/DAM/20190701_20190801_PRC_AS_DAM_REGDOWN.csv\")\n",
    "dfAsRUdamPrices=pd.read_csv(\"Data/AS_Prices/DAM/20190701_20190801_PRC_AS_DAM_REGUP.csv\")\n",
    "\n",
    "#RDU/RU RTM\n",
    "\n",
    "dfAsRDrtmPrices=pd.read_csv(\"Data/AS_Prices/RTM/20190701_20190731_PRC_INTVL_AS_RTM_REGDOWN.csv\")\n",
    "dfAsRUrtmPrices=pd.read_csv(\"Data/AS_Prices/RTM/20190701_20190731_PRC_INTVL_AS_RTM_REGUP.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAsValues(dfAsRDdamPrices,dfAsRUdamPrices,dfAsRDrtmPrices,dfAsRUrtmPrices,int_run_days):\n",
    "\n",
    "    \n",
    "    #Naming Dict\n",
    "    \n",
    "    dctRdDAM={}\n",
    "    dctRuDAM={}\n",
    "    \n",
    "    dctRdRTM={}\n",
    "    dctRuRTM={}  \n",
    "    \n",
    "    dfRTMru=pd.DataFrame()\n",
    "    dfRTMrd=pd.DataFrame()\n",
    "    dfDAMru=pd.DataFrame()\n",
    "    dfDAMrd=pd.DataFrame()\n",
    "    \n",
    "    #get dataframe for each day\n",
    "    for days in range(1,31):\n",
    "        lsRuValue = []\n",
    "        lsRdValue = []\n",
    "        dfRuHolder=dfAsRUdamPrices.loc[(dfAsRUdamPrices['GROUP'])==days].sort_values('OPR_HR').reset_index()\n",
    "        dfRdHolder=dfAsRDdamPrices.loc[(dfAsRDdamPrices['GROUP'])==days].sort_values('OPR_HR').reset_index()\n",
    "        \n",
    "        for intHr in range(24):\n",
    "\n",
    "        # get hourly $/MW price -- convert to 15 minute kWh\n",
    "            fltUp = dfRuHolder['MW'].iloc[intHr]/1000\n",
    "            fltDown = dfRdHolder['MW'].iloc[intHr]/1000\n",
    "\n",
    "            for intInterval in range(4):\n",
    "                lsRuValue.append(fltUp)\n",
    "                lsRdValue.append(fltDown)\n",
    "\n",
    "    # adjust for simulation run period\n",
    "        for ind in range(int_run_days-1):\n",
    "\n",
    "            lsRdValue += lsRdValue\n",
    "            lsRuValue += lsRuValue\n",
    "            \n",
    "        dfDAMru.insert(days-1,str(days),lsRuValue,True)\n",
    "        dfDAMrd.insert(days-1,str(days),lsRdValue,True)\n",
    "       # dctRdDAM[days]=lsRdValue\n",
    "       # dctRuDAM[days]=lsRuValue\n",
    "    \n",
    "    for days in range(1,31):\n",
    "        lsRuValue = []\n",
    "        lsRdValue = []\n",
    "        dfRuHolder=dfAsRUrtmPrices.loc[(dfAsRUrtmPrices['GROUP'])==days].sort_values('OPR_TM').reset_index()\n",
    "        dfRdHolder=dfAsRDrtmPrices.loc[(dfAsRDrtmPrices['GROUP'])==days].sort_values('OPR_TM').reset_index()\n",
    "        \n",
    "        for intHr in range(96):\n",
    "\n",
    "        # get hourly $/MW price -- convert to 15 minute kWh\n",
    "            fltUp = dfRuHolder['MW'].iloc[intHr]/1000\n",
    "            fltDown = dfRuHolder['MW'].iloc[intHr]/1000\n",
    "            \n",
    "            lsRuValue.append(fltUp)\n",
    "            lsRdValue.append(fltDown)\n",
    "\n",
    "    # adjust for simulation run period\n",
    "        for ind in range(int_run_days-1):\n",
    "\n",
    "            lsRdValue += lsRdValue\n",
    "            lsRuValue += lsRuValue\n",
    "            \n",
    "        dfRTMru.insert(days-1,str(days),lsRuValue,True)\n",
    "        dfRTMrd.insert(days-1,str(days),lsRdValue,True)    \n",
    "        \n",
    "    RTMruseries=dfRTMru.sum()\n",
    "    RTMruMax=dfRTMru.iloc[:,int(RTMruseries.idxmax())-1]  \n",
    "    RTMrdseries=dfRTMrd.sum()\n",
    "    RTMrdMax=dfRTMrd.iloc[:,int(RTMrdseries.idxmax())-1]  \n",
    "    DAMruseries=dfDAMru.sum()\n",
    "    DAMruMax=dfDAMru.iloc[:,int(DAMruseries.idxmax())-1]  \n",
    "    DAMrdseries=dfDAMrd.sum()\n",
    "    DAMrdMax=dfDAMrd.iloc[:,int(DAMrdseries.idxmax())-1]  \n",
    "        \n",
    "    return dfRTMru,dfRTMrd,dfDAMru,dfDAMrd, DAMrdMax,DAMruMax,RTMruMax,RTMrdMax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRTMru,dfRTMrd,dfDAMru,dfDAMrd,DAMrdMax,DAMruMax,RTMruMax,RTMrdMax = processAsValues(dfAsRDdamPrices,dfAsRUdamPrices,dfAsRDrtmPrices,dfAsRUrtmPrices,int_run_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.010000\n",
      "1      0.013740\n",
      "2      0.011100\n",
      "3      0.010000\n",
      "4      0.005000\n",
      "         ...   \n",
      "187    0.000000\n",
      "188    0.005990\n",
      "189    0.039490\n",
      "190    0.000999\n",
      "191    0.011000\n",
      "Name: 30, Length: 192, dtype: float64\n",
      "0      0.010000\n",
      "1      0.013740\n",
      "2      0.011100\n",
      "3      0.010000\n",
      "4      0.005000\n",
      "         ...   \n",
      "187    0.000000\n",
      "188    0.005990\n",
      "189    0.039490\n",
      "190    0.000999\n",
      "191    0.011000\n",
      "Name: 30, Length: 192, dtype: float64\n",
      "0      0.018380\n",
      "1      0.018380\n",
      "2      0.018380\n",
      "3      0.018380\n",
      "4      0.011820\n",
      "         ...   \n",
      "187    0.008337\n",
      "188    0.010990\n",
      "189    0.010990\n",
      "190    0.010990\n",
      "191    0.010990\n",
      "Name: 8, Length: 192, dtype: float64\n",
      "0      0.005000\n",
      "1      0.005000\n",
      "2      0.005000\n",
      "3      0.005000\n",
      "4      0.004240\n",
      "         ...   \n",
      "187    0.010678\n",
      "188    0.011257\n",
      "189    0.011257\n",
      "190    0.011257\n",
      "191    0.011257\n",
      "Name: 24, Length: 192, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(RTMrdMax)\n",
    "print(RTMruMax)\n",
    "print(DAMrdMax)\n",
    "print(DAMruMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'TOU_Rate.csv' does not exist: b'TOU_Rate.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-93ae29cbc920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdfGenData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/annual_capfac_15MinInterpolation.csv\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#representative solar day, 15 min interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdfAsPrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/20180701_20180701_PRC_AS_DAM_v1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdfCostElectric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TOU_Rate.csv\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#15 min interal 4-9 pm, I think this is tou B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\evbga\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evbga\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evbga\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evbga\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evbga\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'TOU_Rate.csv' does not exist: b'TOU_Rate.csv'"
     ]
    }
   ],
   "source": [
    "dfTripData = pd.read_csv(\"Data/location_data.csv\")\n",
    "dfLoadData=pd.read_csv(\"Data/use_data_2wk.csv\") #365 days, 1 min increment, 142 houses \n",
    "dfGenData=pd.read_csv(\"Data/annual_capfac_15MinInterpolation.csv\") #representative solar day, 15 min interval\n",
    "dfAsPrices=pd.read_csv('Data/20180701_20180701_PRC_AS_DAM_v1.csv')\n",
    "dfCostElectric=pd.read_csv(\"TOU_Rate.csv\") #15 min interal 4-9 pm, I think this is tou B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "intNumHouseNodes = 5\n",
    "intNumCommNodes = 2\n",
    "intTotalNodes = intNumHouseNodes + intNumCommNodes\n",
    "intAvgNumCarsNode = 5 # goal is to have about 5 * 5 total cars\n",
    "intSdNumCarsNode = 1\n",
    "intProfiles = dfTripData.shape[0]\n",
    "\n",
    "# could make battery parameters a randomized instantiation\n",
    "fltCarEff = 3.95 # mi/kWh\n",
    "fltBatteryCap = 40. # kWh\n",
    "fltChargeRate = 1.9 # kW\n",
    "fltDt = 0.25 # delta T\n",
    "fltHomeRate = 7 # kW\n",
    "fltWorkRate = 7 # kW\n",
    "\n",
    "# time and conversion intervals\n",
    "int_minutes=int(15)\n",
    "int_run_days=2 # day\n",
    "int_run_hours=24 # hours\n",
    "int_run_time_interval=60/int_minutes #\n",
    "time_kwh=15/60  # convert kw data to kwh\n",
    "\n",
    "\n",
    "# cost to charge\n",
    "lsCostElectric = []\n",
    "lsHolder = dfCostElectric.values.tolist()\n",
    "for ind in range(int_run_days):\n",
    "    for n in lsHolder:\n",
    "        lsCostElectric.append(n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCarsNodes(intNumHouseNodes, intNumCommNodes, intAvgNumCarsNode, intSdNumCarsNode, \\\n",
    "                    intProfiles, dfTripData):\n",
    "\n",
    "    '''\n",
    "    Create nodes car trips and assign work and home nodes\n",
    "    '''\n",
    "\n",
    "    #initialize data frame to hold master\n",
    "    dfNodesTrips = pd.DataFrame(columns=['TripId','ResNode','CommNode','HouseID'])\n",
    "    house=int(0)\n",
    "    for intNode in range(intNumHouseNodes):\n",
    "\n",
    "        # find how many vehicles will be at that residential node\n",
    "        intNodeNumCars = int(random.gauss(intAvgNumCarsNode,intSdNumCarsNode))\n",
    "        # assign cars to that node\n",
    "        lsCarIds = [] # container to hold trip id for that node\n",
    "        lsCommNode = [] # container to hold where the commerical node\n",
    "        lsResNode = [] # container to hold the res node\n",
    "        lsVehicleHouses=[] #container to hold the house related to each vehicle/trip\n",
    "        for intCar in range(intNodeNumCars):\n",
    "\n",
    "            # find a car from the data frame\n",
    "            ind = random.randint(0,intProfiles)\n",
    "            lsCarIds.append(dfTripData['ID'].iloc[ind]) # add to car id container\n",
    "\n",
    "            # save res node, added one because 1 initialized index was mismached with comm and load nodes\n",
    "            lsResNode.append(intNode)\n",
    "\n",
    "            # find which commercial node that car goes to\n",
    "            lsCommNode.append(random.randint(0,intNumCommNodes-1))\n",
    "\n",
    "            #add a house id to associate with the trip id\n",
    "            lsVehicleHouses.append(house)\n",
    "\n",
    "            #iterate up house id, 0 based indexing to match the array calls/nodes\n",
    "            house+=int(1)\n",
    "\n",
    "        # create data frame and add to master\n",
    "        dfNode = pd.DataFrame(list(zip(lsCarIds,lsResNode,lsCommNode,lsVehicleHouses)), \\\n",
    "                              columns=['TripId','ResNode','CommNode','HouseID'])\n",
    "\n",
    "        dfNodesTrips = dfNodesTrips.append(dfNode)\n",
    "\n",
    "    dfNodesTrips.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    intVeHouses=house\n",
    "\n",
    "    return dfNodesTrips,intVeHouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAsValues(dfAsPrices,int_run_days):\n",
    "    dfAsPricesRu = dfAsPrices.loc[(dfAsPrices['ANC_REGION'] == 'AS_CAISO_EXP') \\\n",
    "                                    & (dfAsPrices['ANC_TYPE'] == 'RU')].sort_values('OPR_HR').reset_index()\n",
    "    dfAsPricesRd = dfAsPrices.loc[(dfAsPrices['ANC_REGION'] == 'AS_CAISO_EXP') & \\\n",
    "                                  (dfAsPrices['ANC_TYPE'] == 'RD')].sort_values('OPR_HR').reset_index()\n",
    "\n",
    "    lsRuValue = []\n",
    "    lsRdValue = []\n",
    "\n",
    "    for intHr in range(24):\n",
    "\n",
    "        # get hourly $/MW price -- convert to 15 minute kWh\n",
    "        fltUp = dfAsPricesRu['MW'].iloc[intHr]/1000\n",
    "        fltDown = dfAsPricesRd['MW'].iloc[intHr]/1000\n",
    "\n",
    "        for intInterval in range(4):\n",
    "            lsRuValue.append(fltUp)\n",
    "            lsRdValue.append(fltDown)\n",
    "\n",
    "    # adjust for simulation run period\n",
    "    for ind in range(int_run_days-1):\n",
    "\n",
    "        lsRdValue += lsRdValue\n",
    "        lsRuValue += lsRuValue\n",
    "\n",
    "    return lsRuValue, lsRdValue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLoadData(dfLoadData,dfNodesTrips,int_run_days,int_run_hours,int_minutes, intVeHouses,intNumCommNodes,intNumHouseNodes):\n",
    "    '''\n",
    "    process use data from 1 minute intervals to be on 15 minute interals and for specified run time, and associate with nodes and vehicles\n",
    "    Each 24 hour time frame goes from 0 (midnight) to 24 (midnight)\n",
    "    '''\n",
    "    #initialize time frame to pull\n",
    "    minutes=60*int_run_hours\n",
    "    run_length=minutes*int_run_days\n",
    "    intIntervals=int(run_length/int_minutes)\n",
    "\n",
    "    #clean dataframe and convert to numpty for manipulation\n",
    "     #pull only nonzeros columns, but all of them have like one so just set a threshhold\n",
    "    dfLoadData = dfLoadData.dropna(axis=1,thresh=2)\n",
    "    npLoadData=dfLoadData.to_numpy()\n",
    "    run_loads=npLoadData[0:run_length,2:]    # run lenth extracted from dataset, 130+ loads included, skip timestep/day\n",
    "    run_loads=run_loads.astype(\"float32\")#I think iteration is faster in an np array?\n",
    "    #Initialize profile length to pull\n",
    "    intNumLoads = intVeHouses\n",
    "    nLoads=len(run_loads[0,:])\n",
    "\n",
    "    #container for house loads\n",
    "    arrHouseLoads=np.zeros((intNumLoads, intIntervals))  #loadsxtime\n",
    "    #process to 15 minutes fgor houses\n",
    "    for n in range(intNumLoads):\n",
    "        random_select=random.randrange(0,nLoads,1)\n",
    "        house_load_1min=run_loads[:,random_select] #1 house one vehicle\n",
    "        o=int(0)\n",
    "        j=0\n",
    "        while o < (run_length-int_minutes):\n",
    "            start=o\n",
    "            end=o+int_minutes\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('error')\n",
    "            try:\n",
    "                new_interval=np.nanmean(house_load_1min[start:end])\n",
    "            except RuntimeWarning:\n",
    "                new_interval=0  \n",
    "            \n",
    "            arrHouseLoads[n,j]=new_interval\n",
    "            o+=int_minutes\n",
    "            j+=1\n",
    "\n",
    "\n",
    "    #calculate cumulative home nodes\n",
    "    dfNodeLoads=pd.DataFrame()  #rows will be t, columns will be node ID information, reverse of other df for easy lookup by node\n",
    "    dctHomeNode=dict() #save node to id mapping, may be useful\n",
    "    cumulativeLoads=np.zeros((intIntervals))\n",
    "    i=0 #columns in the node dataframe\n",
    "\n",
    "    for n in range(intNumHouseNodes):\n",
    "        #find all the houses that match that Node\n",
    "        NodeID='ResNode'+str(n)\n",
    "        lsHomeNode=dfNodesTrips[dfNodesTrips['ResNode']==int(n)].index.tolist()#all home/vehicles that have that resnode associated in dfNodesTrips\n",
    "        sumrows=arrHouseLoads[lsHomeNode,:]\n",
    "        cumulativeLoads=np.nansum(sumrows,axis=0)  #this should just be one column\n",
    "        dctHomeNode[NodeID]=lsHomeNode\n",
    "        dfNodeLoads.insert(i,NodeID,cumulativeLoads,True)\n",
    "        i+=1\n",
    "\n",
    "    arrCommercialLoads=np.zeros((intIntervals,intNumCommNodes))\n",
    "    #commercial node loads, related to multiple vehicles\n",
    "    for k in range(intNumCommNodes):  #home x10 for commercial, should replace with real commercial values if possible!\n",
    "        random_select=random.randrange(0,nLoads,1)\n",
    "        comm_load_1min=50*run_loads[:,random_select]\n",
    "        o=int(0)\n",
    "        j=0\n",
    "        while o < (run_length-int_minutes):\n",
    "            start=o\n",
    "            end=o+int_minutes\n",
    "            new_interval=np.nanmean(comm_load_1min[start:end])\n",
    "            arrCommercialLoads[j,k]=new_interval\n",
    "            o+=int_minutes\n",
    "            j+=1\n",
    "        dfNodeLoads.insert(i,\"CommNode\"+str(k),arrCommercialLoads[:,k],True)\n",
    "        i+=1\n",
    "\n",
    "    PeakTimes=dfNodeLoads.idxmax()\n",
    "    PeakLoads=dfNodeLoads.max()\n",
    "\n",
    "\n",
    "    lsNodes=dfNodeLoads.columns.values.tolist()\n",
    "    return   arrHouseLoads,dfNodeLoads, PeakTimes,PeakLoads, lsNodes, dctHomeNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNodesTrips, intVeHouses = createCarsNodes(intNumHouseNodes, intNumCommNodes, intAvgNumCarsNode, intSdNumCarsNode, \\\n",
    "                    intProfiles, dfTripData)\n",
    "\n",
    "lsRuValue, lsRdValue = getAsValues(dfAsPrices, int_run_days)\n",
    "\n",
    "arrHouseLoads,dfNodeLoads, PeakTimes,PeakLoads, \\\n",
    "lsNodes,dctHomeNode = convertLoadData(dfLoadData,dfNodesTrips, \\\n",
    "                                    int_run_days,int_run_hours,int_minutes, intVeHouses,intNumCommNodes,intNumHouseNodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ResNode0   ResNode1  ResNode2  ResNode3  ResNode4   CommNode0   CommNode1\n",
      "0    5.119533   9.202333  5.406467  1.098867  1.277000   24.906670   19.343334\n",
      "1    5.824133  10.207933  3.551000  1.172467  1.325067   18.253332  141.276672\n",
      "2    5.252733   9.583200  4.590333  1.665133  1.565933   23.163332   14.136667\n",
      "3    8.995400   8.138800  3.769867  1.279333  1.441867   22.526667   33.083332\n",
      "4    7.550934   4.541933  5.109933  1.070933  1.403067   18.393333   22.240000\n",
      "..        ...        ...       ...       ...       ...         ...         ...\n",
      "187  6.173067  13.516267  3.271800  2.263267  1.237933   96.493332  396.723328\n",
      "188  5.101400  12.082399  3.731667  2.916467  1.309467  123.726677  382.080017\n",
      "189  4.170667  10.580999  2.523933  2.232733  1.182800   68.403328  377.503326\n",
      "190  5.051667  10.025001  3.892533  2.130467  1.044533   58.230003  385.096680\n",
      "191  0.000000   0.000000  0.000000  0.000000  0.000000    0.000000    0.000000\n",
      "\n",
      "[192 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfNodeLoads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
